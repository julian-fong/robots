{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext\n",
    "\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100282\n",
      "{'<|endoftext|>': 100257, '<|fim_prefix|>': 100258, '<|fim_middle|>': 100259, '<|fim_suffix|>': 100260, '<|endofprompt|>': 100276, '<|PAD|>': 0, '<|START|>': 100278, '<|END|>': 100279, '<|DEL|>': 100280, '!': 100281}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#dataset https://nlp.stanford.edu/projects/nmt/\n",
    "\n",
    "#tiktoken api https://github.com/openai/tiktoken\n",
    "cl100k_base = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# In production, load the arguments directly instead of accessing private attributes\n",
    "# See openai_public.py for examples of arguments for specific encodings\n",
    "tokenizer = tiktoken.Encoding(\n",
    "    # If you're changing the set of special tokens, make sure to use a different name\n",
    "    # It should be clear from the name what behaviour to expect.\n",
    "    name=\"cl100k_im\",\n",
    "    pat_str=cl100k_base._pat_str,\n",
    "    mergeable_ranks=cl100k_base._mergeable_ranks,\n",
    "    special_tokens={\n",
    "        **cl100k_base._special_tokens,\n",
    "        \"<|PAD|>\": 0,\n",
    "        \"<|START|>\": 100278,\n",
    "        \"<|END|>\": 100279,\n",
    "        \"<|DEL|>\": 100280,\n",
    "        \"!\": 100281\n",
    "    }\n",
    ")\n",
    "print(tokenizer.n_vocab) #this is the number of tokens in our tokenizer\n",
    "print(tokenizer._special_tokens) #prints out our special tokens \n",
    "\n",
    "specials = {\"<|PAD|>\",\"<|START|>\",\"<|END|>\", \"<|DEL|>\", \"!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n"
     ]
    }
   ],
   "source": [
    "#GLOBALS\n",
    "\n",
    "block_size = 32 #This is the value of T\n",
    "batch_size = 16 #This it the value of B\n",
    "n_embed = 64\n",
    "dropout = 0.2\n",
    "n_heads = 4\n",
    "n_layers = 6\n",
    "\n",
    "learning_rate = 3e-4\n",
    "\n",
    "eval_interval = 500\n",
    "eval_iters = 200\n",
    "max_iters = 2000\n",
    "\n",
    "vocab_size = tokenizer.n_vocab\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device is: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    num_examples = 100000\n",
    "\n",
    "    en_max = 0\n",
    "    en_length = []\n",
    "    with open(os.getcwd()+'\\\\data\\\\train_en.txt', 'r', encoding='utf8') as f:\n",
    "        sentences_en = []\n",
    "        for i in tqdm(range(num_examples)):\n",
    "            line = f.readline()\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            len_pad = 0\n",
    "            sentence = \"<|PAD|> \" + (line) + \" <|PAD|>\"\n",
    "            tok_sentence = tokenizer.encode(sentence, allowed_special = specials)\n",
    "            en_length.append(len(tok_sentence))\n",
    "            if len(tok_sentence) > en_max:\n",
    "                en_max = len(tok_sentence)\n",
    "                print(en_max)\n",
    "\n",
    "            if len(tok_sentence) <= block_size:\n",
    "                len_pad = block_size - len(tok_sentence)\n",
    "                tok_sentence = tok_sentence + len_pad*[0]\n",
    "                assert len(tok_sentence) == block_size, print(len(tok_sentence))\n",
    "                sentences_en.append(tok_sentence)\n",
    "            else:\n",
    "                sentences_en.append(block_size*[100280])\n",
    "\n",
    "    en_length = torch.tensor(en_length).float()     \n",
    "    print(en_max)    \n",
    "    print(f\"Length of sentences: {len(sentences_en)}\")\n",
    "\n",
    "    de_max = 0\n",
    "    de_length = []\n",
    "    with open(os.getcwd()+'\\\\data\\\\train_de.txt', 'r', encoding='utf8') as f:\n",
    "        sentences_de = []\n",
    "        for i in tqdm(range(num_examples)):\n",
    "            line = f.readline()\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            len_pad = 0\n",
    "            sentence = \"<|START|> \" + (line) + \" <|END|>\"\n",
    "            tok_sentence = tokenizer.encode(sentence, allowed_special = specials)\n",
    "            de_length.append(len(tok_sentence))\n",
    "            if len(tok_sentence) > de_max:\n",
    "                de_max = len(tok_sentence)\n",
    "                print(de_max)\n",
    "\n",
    "            if len(tok_sentence) <= block_size:\n",
    "                len_pad = block_size - len(tok_sentence)\n",
    "                tok_sentence = tok_sentence + len_pad*[0]\n",
    "                assert len(tok_sentence) == block_size, print(len(tok_sentence))\n",
    "                sentences_de.append(tok_sentence)\n",
    "            else:\n",
    "                sentences_de.append(block_size*[100280])\n",
    "\n",
    "    de_length = torch.tensor(de_length).float()               \n",
    "    print(de_max) \n",
    "    print(f\"Length of sentences: {len(sentences_de)}\")\n",
    "\n",
    "    print(\"Removing sentences whos length is greater than our block_size\")\n",
    "\n",
    "    #combine the arrays together\n",
    "    sentences = np.array([sentences_en, sentences_de])\n",
    "    #check for indices in both sentences that have rows containing the DEL token\n",
    "    idx = np.where(sentences == 100280)\n",
    "\n",
    "    #delete every row that contains the DEL token\n",
    "    sentences = np.delete(sentences, idx[1], axis = 1)\n",
    "\n",
    "    #splitting to german and english\n",
    "\n",
    "    sentences_en = torch.tensor(sentences[0], dtype=torch.long)\n",
    "    sentences_de = torch.tensor(sentences[1], dtype=torch.long)\n",
    "\n",
    "    print(f\"Length of new english sentences: {len(sentences_en)}\")\n",
    "    print(f\"Length of new german sentences: {len(sentences_de)}\")\n",
    "\n",
    "    print(f\"Average length of english tokenized sentence: {torch.mean(en_length)}, and with std: {torch.std(en_length)}\")\n",
    "    print(f\"Average length of german tokenized sentence: {torch.mean(de_length)}, and with std: {torch.std(de_length)}\")\n",
    "\n",
    "    with open(os.getcwd()+'\\\\data\\\\english_sentences.pkl', 'wb') as f:\n",
    "        pickle.dump(sentences_en, f)\n",
    "\n",
    "    with open(os.getcwd()+'\\\\data\\\\german_sentences.pkl', 'wb') as f:\n",
    "        pickle.dump(sentences_de, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209fe2e26c784aea92f01c77bbce9a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "50\n",
      "60\n",
      "67\n",
      "68\n",
      "82\n",
      "95\n",
      "122\n",
      "125\n",
      "132\n",
      "141\n",
      "154\n",
      "177\n",
      "191\n",
      "203\n",
      "295\n",
      "295\n",
      "Length of sentences: 100000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd55f2c0af04baf917d74c79f8c5558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "73\n",
      "83\n",
      "91\n",
      "105\n",
      "120\n",
      "130\n",
      "135\n",
      "161\n",
      "163\n",
      "187\n",
      "239\n",
      "267\n",
      "284\n",
      "284\n",
      "Length of sentences: 100000\n",
      "Removing sentences whos length is greater than our block_size\n",
      "Length of new english sentences: 34865\n",
      "Length of new german sentences: 34865\n",
      "Average length of english tokenized sentence: 32.97871017456055, and with std: 17.489957809448242\n",
      "Average length of german tokenized sentence: 42.1722297668457, and with std: 22.630157470703125\n"
     ]
    }
   ],
   "source": [
    "create = True\n",
    "if create:\n",
    "    create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN AND VAL DATASETS\n",
    "\n",
    "with open(os.getcwd()+'\\\\data\\\\english_sentences.pkl', 'rb') as f:\n",
    "    english_sentences = pickle.load(f)\n",
    "\n",
    "with open(os.getcwd()+'\\\\data\\\\german_sentences.pkl', 'rb') as f:\n",
    "    german_sentences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH LOADER\n",
    "n = int(0.9*len(english_sentences))\n",
    "\n",
    "train_data_en = english_sentences[:n]\n",
    "val_data_en = english_sentences[n:]\n",
    "\n",
    "train_data_de = german_sentences[:n]\n",
    "val_data_de = german_sentences[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    xdata = train_data_en if \"train\" else train_data_en\n",
    "    ydata = train_data_de if \"train\" else val_data_de\n",
    "    idx = torch.randint(len(xdata), (batch_size,))\n",
    "    print(idx)\n",
    "    x = torch.stack([xdata[i] for i in idx])\n",
    "    t = torch.stack([ydata[i] for i in idx])\n",
    "\n",
    "    #shifting our targets by 1 to the right\n",
    "    y = t[:, 1:]\n",
    "    #to pad the last dimension of the input tensor, pad has the form (padding_left, padding_right)\n",
    "    y = F.pad(input = y, pad = (0,1,0,0), mode = 'constant', value = 0)\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y, t\n",
    "\n",
    "#xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch's positional encoding https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "            x: (T, B, C)\n",
    "            We have to change our shape dimensions in to (T, B, C) and then change it back to (B, T, C) when done\n",
    "\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, decoder = False):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder\n",
    "        self.head_size = head_size\n",
    "        self.Wk = nn.Linear(n_embed, head_size)\n",
    "        self.Wq = nn.Linear(n_embed, head_size)\n",
    "        self.Wv = nn.Linear(n_embed, head_size)\n",
    "\n",
    "        if self.decoder:\n",
    "            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #assume input is of size (B, T, C)\n",
    "        K = self.Wk(x) #(B, T, head_size)\n",
    "        Q = self.Wq(x) #(B, T, head_size)\n",
    "        V = self.Wv(x) #(B, T, head_size)\n",
    "\n",
    "        attention_scores = Q @ K.transpose(-2, -1) * 1/(self.head_size)**(1/2) #(B, T, T)\n",
    "\n",
    "        if self.decoder:\n",
    "            attention_scores = attention_scores.masked_fill(self.tril[:T, :T] == 0, float('-inf')) #(B, T, T)\n",
    "\n",
    "        attention_scores = F.softmax(attention_scores, dim = -1) #(B, T, T)\n",
    "        scores = self.dropout(attention_scores) #(B, T, T)\n",
    "        out = scores @ V #(B, T, T) @ (B, T, head_size) = (B, T, head_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "class crossHead(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.Wk = nn.Linear(n_embed, head_size)\n",
    "        self.Wq = nn.Linear(n_embed, head_size)\n",
    "        self.Wv = nn.Linear(n_embed, head_size)\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, enc_out):\n",
    "        #assume x is of shape (B, T, C)\n",
    "        #assume enc_out is of shape (B, T, C)\n",
    "\n",
    "        K = self.Wk(enc_out) #(B, T, head_size)\n",
    "        Q = self.Wq(x) #(B, T, head_size)\n",
    "        V = self.Wv(enc_out) #(B, T, head_size)\n",
    "\n",
    "        attention_scores = Q @ K.transpose(-2, -1) * 1/(self.head_size)**(1/2) #(B, T, T)\n",
    "        attention_scores = attention_scores.masked_fill(self.tril[:T, :T] == 0, float('-inf')) #(B, T, T)\n",
    "        attention_scores = F.softmax(attention_scores, dim = -1) #(B, T, T)\n",
    "        scores = self.dropout(attention_scores) #(B, T, T)\n",
    "        out = scores @ V #(B, T, head_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, head_size, decoder):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, decoder) for _ in range(n_heads)])\n",
    "        #output of heads is of size (B, T, n_heads*head_size)\n",
    "        self.proj = nn.Linear(head_size * n_heads, n_embed)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([crossHead(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_heads*head_size, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out):\n",
    "        x = torch.cat([h(x, enc_out) for h in self.heads], dim = -1)\n",
    "        x = self.proj(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_embed, 4*n_embed)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4*n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "\n",
    "        self.sa = MultiHeadSelfAttention(head_size, decoder = False)\n",
    "        self.ffw = FeedForward()\n",
    "        self.layernorm1 = nn.LayerNorm(n_embed)\n",
    "        self.layernorm2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #assume input x is of size (B, T, C)\n",
    "        x = self.layernorm1(x) #(B, T, C)\n",
    "        x = x + self.sa(x) #(B, T, C)\n",
    "        x = self.layernorm2(x) #(B, T, C)\n",
    "        x = x = self.ffw(x) #(B, T, C)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DecoderCrossBlock(nn.Module):\n",
    "    #one implementation of the multi head cross attention block in the decoder\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "        self.heads = MultiHeadCrossAttention(head_size)\n",
    "        self.layernorm1 = nn.LayerNorm(n_embed)\n",
    "        self.layernorm2 = nn.LayerNorm(n_embed)\n",
    "        self.ffw = FeedForward()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #assume x is input of shape (B, T, C), x is the output of the decoder self attention layer\n",
    "        #assume x is a list of length 2: first element is the output of the previous hidden layer, and the 2nd element is the output of the encoder\n",
    "        x = x[0]\n",
    "        enc_out = x[1]\n",
    "        \n",
    "        x = self.layernorm1(x) #(B, T, C)\n",
    "        x = x + self.heads(x, enc_out) #(B, T, C)\n",
    "        x = self.layernorm2(x) #(B, T, C)\n",
    "        x = x + self.ffw(x) #(B, T, C)\n",
    "\n",
    "        return [x, enc_out]\n",
    "\n",
    "class DecoderSelfBlock(nn.Module):\n",
    "    #one implementation of the multi head self attention block in the decoder\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        head_size = n_embed//n_heads\n",
    "        self.sa = MultiHeadSelfAttention(head_size, decoder = True)\n",
    "        self.layernorm1 = nn.LayerNorm(n_embed)\n",
    "        self.layernorm2 = nn.LayerNorm(n_embed)\n",
    "        self.ffw = FeedForward()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #assume x is of shape (B, T, C)\n",
    "        x = self.layernorm1(x)\n",
    "        x = x + self.sa(x)\n",
    "        x = self.layernorm2(x)\n",
    "        x = x + self.ffw(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_embedding_matrix_x = nn.Embedding(vocab_size, n_embed)\n",
    "        self.pos_embedding_x = PositionalEncoding(n_embed, dropout = dropout)\n",
    "\n",
    "        self.tok_embedding_matrix_y = nn.Embedding(vocab_size, n_embed)\n",
    "        self.pos_embedding_y = PositionalEncoding(n_embed, dropout = dropout)\n",
    "\n",
    "        self.EncoderBlocks = nn.Sequential(*[EncoderBlock() for _ in range(n_layers)])\n",
    "        self.DecoderSelfBlocks = nn.Sequential(*[DecoderSelfBlock() for _ in range(n_layers)])\n",
    "        self.DecoderCrossBlocks = nn.Sequential(*[DecoderCrossBlock() for _ in range(n_layers)])\n",
    "\n",
    "        self.final_layernorm = nn.LayerNorm(n_embed)\n",
    "        self.final_linear = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, y, targets = None):\n",
    "        B, T = x.shape\n",
    "        C = n_embed\n",
    "        \n",
    "        tok_embed_x = self.tok_embedding_matrix_x(x)\n",
    "        pos_embed_x = self.pos_embedding_x(token_embed_x.view(T,B,C)).view(B, T, C)\n",
    "\n",
    "        tok_embed_y = self.tok_embedding_matrix_y(y)\n",
    "        pos_embed_y = self.pos_embedding_y(token_embed_y.view(T,B,C)).view(B, T, C)\n",
    "\n",
    "        x = tok_embed_x + pos_embed_x\n",
    "        y = tok_embed_y + pos_embed_y\n",
    "\n",
    "        #encoder\n",
    "        enc_out = self.EncoderBlocks(x)\n",
    "\n",
    "        #decoder self\n",
    "        y = self.DecoderSelfBlocks(y)\n",
    "        \n",
    "        #decoder cross\n",
    "        y = self.DecoderCrossBlocks([y, enc_out])\n",
    "\n",
    "        #grab the transformed decoder input from the cross attention layer\n",
    "        y = y[0]\n",
    "        #remaining layers\n",
    "        y = self.final_layernorm(y)\n",
    "        y = self.final_linear(y)\n",
    "\n",
    "        if targets is not None:\n",
    "            print(targets.shape)\n",
    "            logits = y.view(B*T, -1)\n",
    "            targets = targets.view(B*T)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.254266 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = Transformer()\n",
    "m = model.to(device)\n",
    "\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x, t, t = get_batch(split)\n",
    "            logits, loss = model(x, y, t)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb, tb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb, tb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.getcwd()+\"\\\\machine_model\\\\model.pt\"\n",
    "torch.save(model.state_dict(), filepath)\n",
    "print(\"model saved at:\", filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22624, 43153, 64466,  2846,  7700, 43289, 29971, 24214, 58505, 65689,\n",
      "        38889, 27415, 71818, 32024, 39233, 32323])\n"
     ]
    }
   ],
   "source": [
    "xb, yb, t = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_embedding_matrix = nn.Embedding(vocab_size, n_embed)\n",
    "pos_embedding = PositionalEncoding(n_embed, dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embed_x = tok_embedding_matrix(xb) #(B, T, C)\n",
    "B, T, C = token_embed_x.shape\n",
    "pos_embed_x = pos_embedding(token_embed_x.view(T,B,C)).view(B, T, C) #(B, T, C)\n",
    "\n",
    "input = token_embed_x + pos_embed_x #(B, T, C)\n",
    "\n",
    "token_embed_y = tok_embedding_matrix(yb) #(B, T, C)\n",
    "B, T, C = token_embed_y.shape\n",
    "pos_embed_y = pos_embedding(token_embed_y.view(T,B,C)).view(B, T, C) #(B, T, C)\n",
    "\n",
    "target = token_embed_y + pos_embed_y #(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 64, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Head(head_size = 64, decoder = False)\n",
    "e = MultiHeadSelfAttention(64, decoder = False)\n",
    "e = EncoderBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "e(input).shape\n",
    "\n",
    "out_e = e(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Head(head_size = 64, decoder = True)\n",
    "d = MultiHeadSelfAttention(head_size = 64, decoder = True)\n",
    "d = DecoderSelfBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d(target).shape\n",
    "\n",
    "out_d = d(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = crossHead(head_size = 64)\n",
    "c = MultiHeadCrossAttention(head_size = 64)\n",
    "c = DecoderCrossBlock()\n",
    "d = DecoderCrossBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.cat((out_e, out_d), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3266,  0.9439, -0.6072,  ..., -0.8942, -0.2462,  0.5541],\n",
       "         [ 0.3558, -0.0816, -1.0313,  ...,  0.2293, -0.4682,  1.1330],\n",
       "         [ 1.0091, -0.0226, -0.3073,  ..., -1.1772,  0.4133,  1.5344],\n",
       "         ...,\n",
       "         [ 0.7896,  0.3576, -0.5905,  ...,  0.0613, -0.5474,  0.6708],\n",
       "         [ 0.1137,  0.1101, -0.9164,  ...,  0.1007, -0.6001,  0.5187],\n",
       "         [ 0.6944,  0.8457, -0.8022,  ..., -0.2061, -0.3018,  0.6769]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(11.1942, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(xb, yb, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|PAD|>\", allowed_special = specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktoken is great!'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([83, 1609, 5963, 374, 2294, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4ee0b04acb4cacacf37d05d30ef1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|PAD|> iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould . <|PAD|>\n",
      "[0, 11245, 24532, 374, 264, 5644, 369, 1005, 25982, 902, 374, 17551, 439, 264, 1488, 1169, 555, 2231, 1919, 22145, 477, 14654, 304, 279, 51370, 13116, 320, 24359, 883, 315, 279, 9699, 6892, 354, 51370, 662, 220, 0]\n",
      "38\n",
      "38\n",
      "<|PAD|> iron cement protects the ingot against the hot , abrasive steel casting process . <|PAD|>\n",
      "[0, 11245, 24532, 36236, 279, 6892, 354, 2403, 279, 4106, 1174, 94804, 9699, 25146, 1920, 662, 220, 0]\n",
      "18\n",
      "<|PAD|> a fire restant repair cement for fire places , ovens , open fireplaces etc . <|PAD|>\n",
      "[0, 264, 4027, 2800, 519, 13023, 24532, 369, 4027, 7634, 1174, 297, 21778, 1174, 1825, 4027, 27170, 5099, 662, 220, 0]\n",
      "21\n",
      "<|PAD|> Construction and repair of highways and ... <|PAD|>\n",
      "[0, 24987, 323, 13023, 315, 60395, 323, 2564, 220, 0]\n",
      "10\n",
      "<|PAD|> An announcement must be commercial character . <|PAD|>\n",
      "[0, 1556, 17480, 2011, 387, 8518, 3752, 662, 220, 0]\n",
      "10\n",
      "38\n",
      "Length of sentences: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c06345316f748eebf7f5a2b06fc3402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "Length of sentences: 5\n"
     ]
    }
   ],
   "source": [
    "# block_size = 10\n",
    "# num_examples = 5\n",
    "\n",
    "# en_max = 0 \n",
    "# with open(os.getcwd()+'\\\\data\\\\train_en.txt', 'r', encoding='utf8') as f:\n",
    "#     idx_en = []\n",
    "#     sentences_en = []\n",
    "#     for i in tqdm(range(num_examples)):\n",
    "#         line = f.readline()\n",
    "#         line = line.replace(\"\\n\", \"\")\n",
    "#         len_pad = 0\n",
    "#         sentence = \"<|PAD|> \" + (line) + \" <|PAD|>\"\n",
    "#         print(sentence)\n",
    "#         print(tokenizer.encode(sentence, allowed_special = specials))\n",
    "#         tok_sentence = tokenizer.encode(sentence, allowed_special = specials)\n",
    "#         print(len(tok_sentence))\n",
    "#         if len(tok_sentence) > en_max:\n",
    "#             en_max = len(tok_sentence)\n",
    "#             print(en_max)\n",
    "\n",
    "#         if len(tok_sentence) <= block_size:\n",
    "#             len_pad = block_size - len(tok_sentence)\n",
    "#             tok_sentence = tok_sentence + len_pad*[100277]\n",
    "#             assert len(tok_sentence) == block_size, print(len(tok_sentence))\n",
    "#             #idx_en.append(i)\n",
    "#             sentences_en.append(tok_sentence)\n",
    "#         else:\n",
    "#             sentences_en.append(block_size*[100280])\n",
    "\n",
    "# print(en_max)    \n",
    "# print(f\"Length of sentences: {len(sentences_en)}\")\n",
    "\n",
    "\n",
    "# de_max = 0 \n",
    "# with open(os.getcwd()+'\\\\data\\\\train_de.txt', 'r', encoding='utf8') as f:\n",
    "#     idx_de = []\n",
    "#     sentences_de = []\n",
    "#     for i in tqdm(range(num_examples)):\n",
    "#         line = f.readline()\n",
    "#         line = line.replace(\"\\n\", \"\")\n",
    "#         len_pad = 0\n",
    "#         sentence = \"<|START|> \" + (line) + \" <|END|>\"\n",
    "#         tok_sentence = tokenizer.encode(sentence, allowed_special = specials)\n",
    "#         if len(tok_sentence) > de_max:\n",
    "#             de_max = len(tok_sentence)\n",
    "#             print(de_max)\n",
    "\n",
    "#         if len(tok_sentence) <= block_size:\n",
    "#             len_pad = block_size - len(tok_sentence)\n",
    "#             tok_sentence = tok_sentence + len_pad*[100277]\n",
    "#             assert len(tok_sentence) == block_size, print(len(tok_sentence))\n",
    "#             #idx_en.append(i)\n",
    "#             sentences_de.append(tok_sentence)\n",
    "#         else:\n",
    "#             sentences_de.append(block_size*[100280])\n",
    "            \n",
    "# print(de_max)  \n",
    "# print(f\"Length of sentences: {len(sentences_de)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4\n",
      " 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "# sentences = np.array([sentences_en, sentences_de])\n",
    "\n",
    "# idx = np.where(sentences == 100280)\n",
    "# print(idx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = np.delete(sentences, idx[1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(2, 0, 10), dtype=int32)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
